model_params:
  name: "VQVAE"
  input_dim: 6
  hidden_dim: 512
  num_layers: 4
  num_heads: 8
  max_seq_len: 350
  codebook_size: 256
  code_dim: 64

  # Single-stage (no K-Means)
  use_vq: true
  codebook_init_path: ""

  # Early stabilization
  beta: 0.25               # lower commitment early, ramp later
  vq_freeze_steps: 0       # let EMA update immediately

  # Encoder/decoder knobs
  history_drop_prob: 0.3
  zero_ss_in_encoder: true
  label_smoothing: 0.05    # reduce smoothing so SS learns faster

  # Regularizers
  ss_tv_lambda: 0.05
  usage_entropy_lambda: 0.01   # stronger push early, can lower later
  reinit_dead_codes: true
  reinit_prob: 1.0
  dead_usage_threshold: 5      # allow recycling of unused codes

  # Geometry controls
  xyz_align_alpha: 0.9
  dist_lambda: 0.0        # off for first ~10 epochs, then increase to 0.05â€“0.1
  rigid_aug_prob: 0.0     # keep off until model stabilizes
  pairwise_sample_k: 96

  # Skip-memory + schedules
  skip_scale: 1.0
  skip_drop_prob: 0.2
  skip_warmup_steps: 8000
  rigid_aug_warmup_steps: 5000

data_params:
  npy_dir: "/public/home/zhangyangroup/chengshiz/keyuan.zhou/prp-dataset/filtered_curves_npy/"
  train_list: "train_list.txt"
  val_list: "val_list.txt"
  mean_xyz: [59.75617548672732, 57.48255340071842, 67.46183179563933]
  std_xyz:  [114.53544376107905, 120.74113448738537, 118.6619735740254]
  train_batch_size: 256
  val_batch_size: 256
  num_workers: 4
  pin_memory: true

exp_params:
  LR: 0.0005
  ss_weight: 2.0           # boost SS supervision
  weight_decay: 0.0001
  bond_length_weight: 0.0  # off initially, enable later
  bond_angle_weight: 0.0   # off initially, enable later
  manual_seed: 1265

trainer_params:
  gpus: 4
  max_epochs: 120
  strategy: "ddp"
  accelerator: "gpu"
  precision: 32
  log_every_n_steps: 20
  num_sanity_val_steps: 0
  benchmark: true
  enable_progress_bar: true

logging_params:
  save_dir: "./logs/"
  name: "VQVAE-SingleStage-Curriculum"
